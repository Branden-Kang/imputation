{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCFQjtFUeu9iRk5u7q7hqE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXvpR3pNMgVS",
        "outputId": "84e4bed2-a804-42ba-f1be-83823e350213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/10000] - D Loss: 1.3917288780212402, G Loss: 0.6736664772033691\n",
            "Epoch [1000/10000] - D Loss: 0.6212496757507324, G Loss: 0.10290511697530746\n",
            "Epoch [2000/10000] - D Loss: 0.6638607978820801, G Loss: 0.09748324006795883\n",
            "Epoch [3000/10000] - D Loss: 0.6097010970115662, G Loss: 0.1165543720126152\n",
            "Epoch [4000/10000] - D Loss: 0.6027552485466003, G Loss: 0.10586100816726685\n",
            "Epoch [5000/10000] - D Loss: 0.6286892294883728, G Loss: 0.1008196473121643\n",
            "Epoch [6000/10000] - D Loss: 0.6297664642333984, G Loss: 0.1113738864660263\n",
            "Epoch [7000/10000] - D Loss: 0.6012288331985474, G Loss: 0.10717393457889557\n",
            "Epoch [8000/10000] - D Loss: 0.6314849257469177, G Loss: 0.10791406035423279\n",
            "Epoch [9000/10000] - D Loss: 0.6253261566162109, G Loss: 0.1045333743095398\n",
            "Original Data:\n",
            "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548 ]\n",
            " [0.64589411 0.43758721 0.891773   0.96366276 0.38344152]\n",
            " [0.79172504 0.52889492 0.56804456 0.92559664 0.07103606]\n",
            " [0.0871293  0.0202184  0.83261985 0.77815675 0.87001215]\n",
            " [0.97861834 0.79915856 0.46147936 0.78052918 0.11827443]]\n",
            "Data with Missing Values:\n",
            "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548 ]\n",
            " [0.64589411 0.43758721 0.891773   0.96366276 0.38344152]\n",
            " [0.         0.52889492 0.56804456 0.92559664 0.07103606]\n",
            " [0.0871293  0.0202184  0.83261985 0.77815675 0.        ]\n",
            " [0.97861834 0.79915856 0.46147936 0.78052918 0.11827443]]\n",
            "Imputed Data:\n",
            "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548 ]\n",
            " [0.64589411 0.43758721 0.891773   0.96366276 0.38344152]\n",
            " [0.01354936 0.52889492 0.56804456 0.92559664 0.07103606]\n",
            " [0.0871293  0.0202184  0.83261985 0.77815675 0.93708032]\n",
            " [0.97861834 0.79915856 0.46147936 0.78052918 0.11827443]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Define generator model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "# Define discriminator model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim),  # Match output size to input_dim\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "# Utility function to introduce missing values\n",
        "def introduce_missing_values(data, missing_rate=0.2):\n",
        "    data_with_missing = data.copy()\n",
        "    mask = np.random.binomial(1, 1 - missing_rate, data.shape)\n",
        "    data_with_missing[mask == 0] = 0\n",
        "    return data_with_missing, mask\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = 5  # Number of features\n",
        "batch_size = 64\n",
        "epochs = 10000\n",
        "lr = 1e-3\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "data = np.random.rand(1000, input_dim)\n",
        "data_with_missing, mask = introduce_missing_values(data, missing_rate=0.2)\n",
        "\n",
        "# Convert to torch tensors\n",
        "data_tensor = torch.FloatTensor(data)\n",
        "data_missing_tensor = torch.FloatTensor(data_with_missing)\n",
        "mask_tensor = torch.FloatTensor(mask)\n",
        "\n",
        "# Initialize models\n",
        "G = Generator(input_dim)\n",
        "D = Discriminator(input_dim)\n",
        "\n",
        "# Optimizers\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=lr)\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=lr)\n",
        "\n",
        "# Loss functions\n",
        "bce_loss = nn.BCELoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Generate imputations\n",
        "    G_sample = G(data_missing_tensor)\n",
        "\n",
        "    # Combine the generated and known data\n",
        "    data_hat = data_missing_tensor * mask_tensor + G_sample * (1 - mask_tensor)\n",
        "\n",
        "    # Discriminator forward pass\n",
        "    D_prob = D(data_hat)\n",
        "    real_data_prob = D(data_tensor)\n",
        "\n",
        "    # Loss for discriminator\n",
        "    D_loss = bce_loss(D_prob, mask_tensor) + bce_loss(real_data_prob, torch.ones_like(real_data_prob))\n",
        "\n",
        "    # Optimize discriminator\n",
        "    d_optimizer.zero_grad()\n",
        "    D_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    # Generator forward pass\n",
        "    G_sample = G(data_missing_tensor)\n",
        "    data_hat = data_missing_tensor * mask_tensor + G_sample * (1 - mask_tensor)\n",
        "\n",
        "    # Discriminator output with imputed data\n",
        "    D_prob = D(data_hat)\n",
        "\n",
        "    # Loss for generator\n",
        "    G_loss = bce_loss(D_prob, torch.ones_like(D_prob))\n",
        "\n",
        "    # Optimize generator\n",
        "    g_optimizer.zero_grad()\n",
        "    G_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f'Epoch [{epoch}/{epochs}] - D Loss: {D_loss.item()}, G Loss: {G_loss.item()}')\n",
        "\n",
        "# Impute missing values with the trained generator\n",
        "with torch.no_grad():\n",
        "    imputed_data = G(data_missing_tensor).numpy()\n",
        "    imputed_data = data_with_missing * mask + imputed_data * (1 - mask)\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(data[:5])\n",
        "print(\"Data with Missing Values:\")\n",
        "print(data_with_missing[:5])\n",
        "print(\"Imputed Data:\")\n",
        "print(imputed_data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Original data\n",
        "original_data = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "jiJ13Q53cFnC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# MSE calculation function\n",
        "def calculate_mse(true_values, imputed_values):\n",
        "    mse = mean_squared_error(true_values, imputed_values)\n",
        "    return mse\n",
        "\n",
        "gain_mse = calculate_mse(original_data, imputed_data)\n",
        "\n",
        "print(f\"GAIN MSE: {gain_mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLT6nW8xaYxk",
        "outputId": "6b476d2c-80d9-408c-83ac-63235ff92fb4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAIN MSE: 0.039217004875565585\n"
          ]
        }
      ]
    }
  ]
}