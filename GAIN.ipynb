{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLs7pJtwZGIcsvaRTOSU53"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXvpR3pNMgVS",
        "outputId": "9bce5143-8606-4410-a4e9-ea361cf8f61d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/10000] - D Loss: 1.3789055347442627, G Loss: 0.6722905039787292\n",
            "Epoch [1000/10000] - D Loss: 0.6118221879005432, G Loss: 0.10541795939207077\n",
            "Epoch [2000/10000] - D Loss: 0.6141912341117859, G Loss: 0.10770110040903091\n",
            "Epoch [3000/10000] - D Loss: 0.5924171209335327, G Loss: 0.10522453486919403\n",
            "Epoch [4000/10000] - D Loss: 0.5922989249229431, G Loss: 0.1070709377527237\n",
            "Epoch [5000/10000] - D Loss: 0.5815091133117676, G Loss: 0.10766290128231049\n",
            "Epoch [6000/10000] - D Loss: 0.5929068922996521, G Loss: 0.10830793529748917\n",
            "Epoch [7000/10000] - D Loss: 0.5765272378921509, G Loss: 0.10705052316188812\n",
            "Epoch [8000/10000] - D Loss: 0.579983115196228, G Loss: 0.10592798888683319\n",
            "Epoch [9000/10000] - D Loss: 0.5512576103210449, G Loss: 0.10675715655088425\n",
            "Original Data:\n",
            "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548 ]\n",
            " [0.64589411 0.43758721 0.891773   0.96366276 0.38344152]\n",
            " [0.79172504 0.52889492 0.56804456 0.92559664 0.07103606]\n",
            " [0.0871293  0.0202184  0.83261985 0.77815675 0.87001215]\n",
            " [0.97861834 0.79915856 0.46147936 0.78052918 0.11827443]]\n",
            "Data with Missing Values:\n",
            "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548 ]\n",
            " [0.64589411 0.43758721 0.891773   0.96366276 0.38344152]\n",
            " [0.         0.52889492 0.56804456 0.92559664 0.07103606]\n",
            " [0.0871293  0.0202184  0.83261985 0.77815675 0.        ]\n",
            " [0.97861834 0.79915856 0.46147936 0.78052918 0.11827443]]\n",
            "Imputed Data:\n",
            "[[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548 ]\n",
            " [0.64589411 0.43758721 0.891773   0.96366276 0.38344152]\n",
            " [0.20316102 0.52889492 0.56804456 0.92559664 0.07103606]\n",
            " [0.0871293  0.0202184  0.83261985 0.77815675 0.60087168]\n",
            " [0.97861834 0.79915856 0.46147936 0.78052918 0.11827443]]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Define generator model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "# Define discriminator model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim),  # Match output size to input_dim\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "# Utility function to introduce missing values\n",
        "def introduce_missing_values(data, missing_rate=0.2):\n",
        "    data_with_missing = data.copy()\n",
        "    mask = np.random.binomial(1, 1 - missing_rate, data.shape)\n",
        "    data_with_missing[mask == 0] = 0\n",
        "    return data_with_missing, mask\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = 5  # Number of features\n",
        "batch_size = 64\n",
        "epochs = 10000\n",
        "lr = 1e-3\n",
        "\n",
        "# Generate sample data\n",
        "np.random.seed(0)\n",
        "data = np.random.rand(1000, input_dim)\n",
        "data_with_missing, mask = introduce_missing_values(data, missing_rate=0.2)\n",
        "\n",
        "# Convert to torch tensors\n",
        "data_tensor = torch.FloatTensor(data)\n",
        "data_missing_tensor = torch.FloatTensor(data_with_missing)\n",
        "mask_tensor = torch.FloatTensor(mask)\n",
        "\n",
        "# Initialize models\n",
        "G = Generator(input_dim)\n",
        "D = Discriminator(input_dim)\n",
        "\n",
        "# Optimizers\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=lr)\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=lr)\n",
        "\n",
        "# Loss functions\n",
        "bce_loss = nn.BCELoss()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Generate imputations\n",
        "    G_sample = G(data_missing_tensor)\n",
        "\n",
        "    # Combine the generated and known data\n",
        "    data_hat = data_missing_tensor * mask_tensor + G_sample * (1 - mask_tensor)\n",
        "\n",
        "    # Discriminator forward pass\n",
        "    D_prob = D(data_hat)\n",
        "    real_data_prob = D(data_tensor)\n",
        "\n",
        "    # Loss for discriminator\n",
        "    D_loss = bce_loss(D_prob, mask_tensor) + bce_loss(real_data_prob, torch.ones_like(real_data_prob))\n",
        "\n",
        "    # Optimize discriminator\n",
        "    d_optimizer.zero_grad()\n",
        "    D_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    # Generator forward pass\n",
        "    G_sample = G(data_missing_tensor)\n",
        "    data_hat = data_missing_tensor * mask_tensor + G_sample * (1 - mask_tensor)\n",
        "\n",
        "    # Discriminator output with imputed data\n",
        "    D_prob = D(data_hat)\n",
        "\n",
        "    # Loss for generator\n",
        "    G_loss = bce_loss(D_prob, torch.ones_like(D_prob))\n",
        "\n",
        "    # Optimize generator\n",
        "    g_optimizer.zero_grad()\n",
        "    G_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f'Epoch [{epoch}/{epochs}] - D Loss: {D_loss.item()}, G Loss: {G_loss.item()}')\n",
        "\n",
        "# Impute missing values with the trained generator\n",
        "with torch.no_grad():\n",
        "    imputed_data = G(data_missing_tensor).numpy()\n",
        "    imputed_data = data_with_missing * mask + imputed_data * (1 - mask)\n",
        "\n",
        "print(\"Original Data:\")\n",
        "print(data[:5])\n",
        "print(\"Data with Missing Values:\")\n",
        "print(data_with_missing[:5])\n",
        "print(\"Imputed Data:\")\n",
        "print(imputed_data[:5])"
      ]
    }
  ]
}